{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ccf00c-4e88-4f65-9fbe-9ac7108c5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook():\n",
    "    try:\n",
    "        __IPYTHON__\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371a013-679b-4ce4-b5e7-24d69b50dde1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "import hydra\n",
    "\n",
    "if is_notebook():\n",
    "    with initialize(config_path=\"conf/\"):\n",
    "        cfg = compose(config_name=\"config.yaml\", overrides=[])#[\"+db=mysql\"])\n",
    "else:\n",
    "    @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
    "    def get_cfg(cfg):\n",
    "        return dict(cfg)\n",
    "    cfg = get_cfg()\n",
    "print(cfg)\n",
    "locals().update(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48329d11-cea0-407c-8906-15848df60b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook():\n",
    "    # override variables to experiment in notebook\n",
    "    gpu = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274dffd-8fd3-40b1-ac80-56a4a83db9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "root_folder = \"/raid/8wiehe/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a70f8-33cb-4d83-995b-f437779b414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(cfg)[\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23942d90-e107-4901-9a27-db40349a31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2424212-d114-4473-abd4-361ca2040a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch_size is None:\n",
    "    if model_name == \"ViT-L/14\":\n",
    "        batch_size = 4 # max 32 for single GPU CL on VitB16, 4 for ViT-L/14 (9.2GB)\n",
    "    elif model_name == \"ViT-B/16\":\n",
    "        batch_size = 32\n",
    "    elif model_name == \"ViT-B/32\":\n",
    "        batch_size = 64\n",
    "    else:\n",
    "        batch_size = 32\n",
    "\n",
    "val_check_interval = int(cfg[\"val_check_interval\"] * (32 / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d7b39-94b9-4079-be74-3b3c597b720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip_utils import load_clip, FinetuneDataModule\n",
    "from contrastive_learning_utils import LitCLCLIP\n",
    "\n",
    "clip_base_model, transform, clip_name = load_clip(model_name, device=\"cpu\")\n",
    "\n",
    "data_module = FinetuneDataModule(clip_base_model, transform, dataset_name=dataset_name, mode=mode, \n",
    "                                 use_augs=use_augs, use_cl=True, sent_frac=sent_frac, batch_size=batch_size,\n",
    "                                root_folder=root_folder, use_ffcv=use_ffcv)\n",
    "\n",
    "lit_model = LitCLCLIP(clip_base_model, mode, max_epochs, lr, data_module.steps_per_epoch, \n",
    "                 weight_decay=weight_decay, gen_freq=gen_freq)\n",
    "lit_model.label_names = data_module.label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf56bc-b419-4ec2-aeb7-04ddb74ef541",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_module.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee821c2-1384-4d5a-81d5-acbddc548831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pytorch_lightning\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# for ffcv\n",
    "if use_ffcv:\n",
    "    from types import MethodType\n",
    "    import ffcv_custom_PTL_methods \n",
    "\n",
    "\n",
    "wandb_logger = pytorch_lightning.loggers.WandbLogger(name=None, \n",
    "                                                     save_dir=root_folder + \"pytorch_lightning/\", \n",
    "                                                     offline=False, id=None, \n",
    "                                      anonymous=None, version=None, project=\"cl_early_tests\", \n",
    "                                      log_model=False, experiment=None, prefix='')\n",
    "wandb_logger.log_hyperparams({\"mode\": mode,\n",
    "                              \"dataset_name\": dataset_name,\n",
    "                              \"sent_frac\": sent_frac,\n",
    "                              \"use_augs\": use_augs,\n",
    "                              \"batch_size\": batch_size,\n",
    "                              \"model_name\": model_name,\n",
    "                              \"use_ffcv\": use_ffcv,\n",
    "                             })\n",
    "# log gradients and model topology\n",
    "wandb_logger.watch(lit_model)\n",
    "\n",
    "\n",
    "trainer = pytorch_lightning.Trainer(val_check_interval=val_check_interval,\n",
    "                                    precision=precision,\n",
    "                                    logger=wandb_logger,\n",
    "                                    max_epochs=max_epochs,\n",
    "                                    gpus=int(torch.cuda.is_available()),\n",
    "                                    #overfit_batches=1, \n",
    "                                    benchmark=True,\n",
    "                                    )\n",
    "\n",
    "if use_ffcv:\n",
    "    # for ffcv\n",
    "    trainer.fit_loop.epoch_loop.on_run_start = MethodType(custom_PTL_methods.on_run_start, trainer.fit_loop.epoch_loop)\n",
    "    trainer.fit_loop.epoch_loop.advance = MethodType(custom_PTL_methods.advance, trainer.fit_loop.epoch_loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f72ac-3be9-4c99-8b16-0e3c86bed09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(lit_model, data_module)\n",
    "# remove wandb hooks\n",
    "#wandb_logger.unwatch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e66afc-bfab-40b8-98ca-8c380fa30bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.val_check_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec7252-9c0d-4510-a9ad-29e79149b732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
